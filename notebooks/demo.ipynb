{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Demonstrating Attention Mechanism and Memory Bank Functionality\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will explore the functionality of the Attention and Memory Bank models implemented in PyTorch. Attention mechanisms are crucial for improving the performance of various machine learning tasks, especially in natural language processing and computer vision.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Installation and Imports\n",
    "#import python\n",
    "\n",
    "# Imports\n",
    "%pip uninstall torch torchvision torchaudio\n",
    "\n",
    "%pip install torch torchvision torchaudio\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the model directory to the system path\n",
    "sys.path.append(r'C:\\Users\\user\\Desktop\\GRAPHFUSSION\\graphfusion-challenge\\model')\n",
    "\n",
    "# Now import torch and your model classes\n",
    "import torch\n",
    "from attention import Attention  # Assuming the attention.py file is directly in the model directory\n",
    "from memory import MemoryBank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Attention' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize models\u001b[39;00m\n\u001b[0;32m      2\u001b[0m feature_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 3\u001b[0m attention_model \u001b[38;5;241m=\u001b[39m Attention(feature_dim)\n\u001b[0;32m      4\u001b[0m memory_bank_model \u001b[38;5;241m=\u001b[39m MemoryBank()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Attention' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "feature_dim = 10\n",
    "attention_model = Attention(feature_dim)\n",
    "memory_bank_model = MemoryBank()  # Assuming default constructor is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "memory_size = 5\n",
    "query = torch.randn(batch_size, feature_dim)\n",
    "keys = torch.randn(batch_size, memory_size, feature_dim)\n",
    "values = torch.randn(batch_size, memory_size, feature_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_output = attention_model(query, keys, values)\n",
    "print(\"Attention Output:\", attention_output)\n",
    "# Example usage for MemoryBank, depending on its methods\n",
    "memory_output = memory_bank_model.write(query)\n",
    "print(\"Memory Output:\", memory_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Measure execution time for attention model\n",
    "start_time = time.time()\n",
    "attention_output = attention_model(query, keys, values)\n",
    "execution_time = time.time() - start_time\n",
    "print(\"Execution Time for Attention Model:\", execution_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(attention_weights.detach().numpy(), cmap='viridis')\n",
    "plt.title(\"Attention Weights\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
