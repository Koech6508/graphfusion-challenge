{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory-Augmented Neural Network Demo\n",
    "This notebook demonstrates the functionality of a memory-augmented neural network that can store and retrieve information from a memory bank, implement attention-based memory access, calculate confidence scores for retrievals, and demonstrate learning over sequential data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/sophy/graphfusion-challenge\")\n",
    "from model.memory import MemoryBank, ConfidenceScoring\n",
    "from data.data_generator import generate_sequence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "seq_length = 10        # Length of sequences\n",
    "feature_dim = 8        # Dimension of features\n",
    "batch_size = 16        # Number of sequences in each batch\n",
    "memory_size = 32       # Number of memory slots\n",
    "learning_rate = 0.001  # Learning rate\n",
    "num_epochs = 5         # Number of training epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequences Shape: torch.Size([16, 10, 8])\n",
      "Target Sequences Shape: torch.Size([16, 10, 8])\n"
     ]
    }
   ],
   "source": [
    "# Generate sequential data\n",
    "input_sequences, target_sequences = generate_sequence_data(seq_length, feature_dim, batch_size)\n",
    "\n",
    "print(\"Input Sequences Shape:\", input_sequences.shape)\n",
    "print(\"Target Sequences Shape:\", target_sequences.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Memory Bank and Confidence Scoring\n",
    "memory_bank = MemoryBank(memory_size=memory_size, feature_dim=feature_dim)\n",
    "confidence_scorer = ConfidenceScoring(feature_dim)\n",
    "# After initializing MemoryBank and ConfidenceScoring\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(memory_bank.parameters()) + list(confidence_scorer.parameters()),\n",
    "    lr=learning_rate\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sophy\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([10, 8])) that is different to the input size (torch.Size([1, 8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.1684\n",
      "Epoch 2/5, Loss: 0.0838\n",
      "Epoch 3/5, Loss: 0.1475\n",
      "Epoch 4/5, Loss: 0.3403\n",
      "Epoch 5/5, Loss: 0.6492\n"
     ]
    }
   ],
   "source": [
    "# Define a simple Mean Squared Error loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(batch_size):\n",
    "        # Extract the appropriate input sequence for the current index\n",
    "        input_sequence = input_sequences[i]  # Shape (seq_length, feature_dim)\n",
    "        \n",
    "        # Reshape input_sequence to match the expected input data shape (1, feature_dim)\n",
    "        input_sequence = input_sequence[-1].unsqueeze(0)  # Use the last timestep, shape (1, feature_dim)\n",
    "        \n",
    "        # Write to memory\n",
    "        write_weights = torch.ones(1, memory_size) / memory_size  # Shape (1, memory_size)\n",
    "        memory_bank.write(input_sequence, write_weights)\n",
    "        \n",
    "        # Retrieve data from memory\n",
    "        retrieved_memory, _ = memory_bank.read(input_sequence)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(retrieved_memory, target_sequences[i])\n",
    "        \n",
    "        # Backpropagation (assuming optimizer is defined elsewhere)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Test Input Shape: torch.Size([10, 8])\n",
      "Test Input: tensor([[0.9660, 0.0498, 0.4853, 0.7602, 0.0199, 0.6989, 0.8146, 0.5031],\n",
      "        [0.3014, 0.4729, 0.9222, 0.6524, 0.1770, 0.6331, 0.4730, 0.0851],\n",
      "        [0.9899, 0.7812, 0.8622, 0.6188, 0.1208, 0.7936, 0.4908, 0.0949],\n",
      "        [0.6297, 0.8746, 0.2662, 0.6311, 0.3014, 0.3592, 0.0244, 0.9470],\n",
      "        [0.3352, 0.1314, 0.9045, 0.8858, 0.6027, 0.6463, 0.4954, 0.1524],\n",
      "        [0.0314, 0.3477, 0.9629, 0.2460, 0.9476, 0.9162, 0.0715, 0.1833],\n",
      "        [0.8146, 0.8403, 0.0434, 0.5029, 0.0247, 0.8999, 0.8866, 0.9748],\n",
      "        [0.7497, 0.3686, 0.7897, 0.7560, 0.1014, 0.5805, 0.9760, 0.0107],\n",
      "        [0.3933, 0.4537, 0.3019, 0.4786, 0.5196, 0.3242, 0.0339, 0.5363],\n",
      "        [0.9830, 0.9865, 0.0206, 0.5675, 0.4898, 0.0313, 0.6223, 0.2567]])\n",
      "Retrieved Memory: tensor([[1.8219, 1.2503, 1.0000, 1.6300, 1.3497, 1.2919, 1.2620, 1.5660],\n",
      "        [1.8219, 1.2503, 1.0000, 1.6300, 1.3497, 1.2919, 1.2620, 1.5660],\n",
      "        [1.8219, 1.2503, 1.0000, 1.6300, 1.3497, 1.2919, 1.2620, 1.5660],\n",
      "        [1.8219, 1.2503, 1.0000, 1.6300, 1.3497, 1.2919, 1.2620, 1.5660],\n",
      "        [1.8219, 1.2503, 1.0000, 1.6300, 1.3497, 1.2919, 1.2620, 1.5660],\n",
      "        [1.8219, 1.2503, 1.0000, 1.6300, 1.3497, 1.2919, 1.2620, 1.5660],\n",
      "        [1.8219, 1.2503, 1.0000, 1.6300, 1.3497, 1.2919, 1.2620, 1.5660],\n",
      "        [1.8219, 1.2503, 1.0000, 1.6300, 1.3497, 1.2919, 1.2620, 1.5660],\n",
      "        [1.8219, 1.2503, 1.0000, 1.6300, 1.3497, 1.2919, 1.2620, 1.5660],\n",
      "        [1.8219, 1.2503, 1.0000, 1.6300, 1.3497, 1.2919, 1.2620, 1.5660]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example of storing and retrieving data\n",
    "test_input = input_sequences[0]  # Use the first input sequence as a test\n",
    "\n",
    "# Print shape for debugging\n",
    "print(\"Original Test Input Shape:\", test_input.shape)\n",
    "\n",
    "# Ensure write_weights has the correct shape for batch processing\n",
    "write_weights = (torch.ones(test_input.size(0), memory_size) / memory_size)  # Shape (10, memory_size)\n",
    "\n",
    "# Write to memory\n",
    "memory_bank.write(test_input, write_weights)  # Ensure test_input is 2D (10, feature_dim)\n",
    "retrieved_memory, _ = memory_bank.read(test_input)  # Ensure test_input is 2D (10, feature_dim)\n",
    "\n",
    "print(\"Test Input:\", test_input)\n",
    "print(\"Retrieved Memory:\", retrieved_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
